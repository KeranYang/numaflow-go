syntax = "proto3";

option go_package = "github.com/numaproj/numaflow-go/pkg/apis/proto/source/v1";

import "google/protobuf/timestamp.proto";
import "google/protobuf/empty.proto";

package source.v1;

service UserDefinedSource {
  // Read returns a stream of datum responses.
  // The size of the returned ReadResponse is less than or equal to the num_records specified in ReadRequest.
  rpc Read(ReadRequest) returns (stream ReadResponse);

  // Ack acknowledges a list of datum offsets.
  // It indicates that the datum stream has been processed by the source vertex.
  rpc Ack(AckRequest) returns (AckResponse);

  // Pending returns the number of pending records at the user defined source.
  rpc Pending(google.protobuf.Empty) returns (PendingResponse);

  // IsSourceReady is the heartbeat endpoint for user defined source gRPC.
  rpc IsSourceReady(google.protobuf.Empty) returns (SourceReadyResponse);
}

/*
 * EventTime represents the event time of the datum.
 */
message EventTime {
  google.protobuf.Timestamp event_time = 1;
}

/*
 * ReadRequest is the request for reading datum stream from user defined source.
 */
message ReadRequest {
  message Request {
    // num_records is the number of records to read.
    uint64 num_records = 1;
  }
  Request request = 1;
}

/*
 * ReadResponse represents a list of datum response elements.
 */
message ReadResponse {
  message Result {
    // elements is a list of datum response elements.
    repeated DatumResponse elements = 1;
  }
  Result result = 1;
}

/*
 * DatumResponse represents a datum response element.
 */
message DatumResponse {
  message Result {
    // payload is the payload of the datum.
    bytes payload = 1;
    // offset is the offset information of the datum.
    Offset offset = 2;
    // keys is an optional list of keys associated with the datum.
    // Key is the "key" attribute in (key,value) as in the map-reduce paradigm.
    // We add this optional field to support the use case where the user defined source can provide keys for the datum.
    // e.g. Kafka and Redis Stream message usually include information about the keys.
    repeated string keys = 3;
    // event_time is the time associated with each datum.
    // We add this optional field to support the use case where the user defined source can provide event time for the datum.
    // e.g. Kafka and Redis Stream message usually include information about the event time.
    EventTime event_time = 4;
  }
  Result result = 1;
}

/*
 * AckRequest is the request for acknowledging datum.
 * It takes a list of offsets to be acknowledged.
 */
message AckRequest {
  message Request {
    repeated Offset offsets = 1;
  }
  Request request = 1;
}

/*
 * AckResponse is the response for acknowledging datum.
 */
message AckResponse {
  message Result {
    // non_acked_offsets is a list of offsets that have not been acknowledged by source.
    // numaflow will retry to acknowledge these offsets.
    repeated Offset non_acked_offsets = 1;
  }
  Result result = 1;
}

/*
 * SourceReadyResponse is the health check result for user defined source.
 */
message SourceReadyResponse {
  bool ready = 1;
}

/*
 * PendingResponse is the response for the pending request.
 */
message PendingResponse {
  message Result {
    // count is the number of pending records at the user defined source.
    uint64 count = 1;
  }
  Result result = 1;
}

/*
 * Offset is the offset of the datum.
 */
message Offset {
  // offset is the offset of the datum.
  // We define Offset as a byte array because different input data sources can have different representations for Offset.
  // The only way to generalize it is to define it as a byte array,
  // Such that we can let the UDSource to de-serialize the offset using its own interpretation logics.
  bytes offset = 1;
  // optional partition_id indicates which partition of the source the datum belongs to.
  // It is useful for sources that have multiple partitions. e.g. Kafka.
  // If the partition_id is not specified, it is assumed that the source has a single partition.
  string partition_id = 2;
}